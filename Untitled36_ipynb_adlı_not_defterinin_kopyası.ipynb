{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled36.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOd0qO5EwGDrxvlCFEly9fg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mertemreozturk/Design-Project/blob/main/Untitled36_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_shape = (50,224,224,3)\n",
        "# num_classes = 2\n",
        "# batch_size = 4\n",
        "\n",
        "# feature_extractor_model = \"https://tfhub.dev/deepmind/i3d-kinetics-400/1\"\n",
        "\n",
        "# feature_extractor_layer = hub.KerasLayer(\n",
        "#     feature_extractor_model,\n",
        "#     input_shape=input_shape,\n",
        "#     trainable=False)\n",
        "\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#   feature_extractor_layer,\n",
        "#   tf.keras.layers.Dense(num_classes)\n",
        "# ])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "nvIkZsN-jrgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_classes = 2\n",
        "# image_size = 224\n",
        "# batch_size = 10\n",
        "# max_frames = 100\n",
        "# input_shape= tf.constant([10,100,224,224,3])\n",
        "# model = tf.keras.Sequential([hub.KerasLayer(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\",trainable=False), \n",
        "#                              tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
        "# model.build([10, 100, 224, 224, 3])\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "3skbLOOhjjZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "id": "YbE_WakVi55D",
        "outputId": "c847fb66-0e2d-4956-8c8c-cfae0d84bc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "import numpy as np\n",
        "import time\n",
        "from imutils import paths\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from absl import logging\n",
        "\n",
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "# Some modules to help with reading the UCF101 dataset.\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "# import skvideo.io\n",
        "# Some modules to display an animation using imageio.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import SGD # optimizer\n",
        "\n",
        "import datetime\n",
        "\n",
        "%load_ext tensorboard\n",
        "#@title \n",
        "# TensorFlow and TF-Hub modules.\n",
        "from absl import logging\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "# Some modules to help with reading the UCF101 dataset.\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython import display\n",
        "\n",
        "from urllib import request  # requires python3\n",
        "\n",
        "# Utilities to open video files using CV2\n",
        "def crop_center_square(frame):\n",
        "  y, x = frame.shape[0:2]\n",
        "  min_dim = min(y, x)\n",
        "  start_x = (x // 2) - (min_dim // 2)\n",
        "  start_y = (y // 2) - (min_dim // 2)\n",
        "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(224, 224)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      frame = crop_center_square(frame)\n",
        "      frame = cv2.resize(frame, resize)\n",
        "      frame = frame[:, :, [2, 1, 0]]\n",
        "      frames.append(frame)\n",
        "      \n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames) / 255.0\n",
        "\n",
        "def to_gif(images):\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave('./animation.gif', converted_images, fps=25)\n",
        "  return embed.embed_file('./animation.gif')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_frames(path, fr=0, max_frames=0, resize=(224, 224)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  count=0\n",
        "  max_frames += 4\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "      if count%fr == 0:\n",
        "\n",
        "        frame = crop_center_square(frame)\n",
        "        frame = cv2.resize(frame, resize)\n",
        "        frame = frame[:, :, [2, 1, 0]]\n",
        "        frames.append(frame)        \n",
        "      count += 1\n",
        "\n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames[4:]) / 255.0\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "imagePaths = list(paths.list_files('/content/drive/MyDrive/movie_data'))\n",
        "video_number = len(imagePaths)\n",
        "# video_array = np.ndarzerosray((1, max_frames, 224, 224, 3), dtype=np.float32)\n",
        "array_of_videos2 = []\n",
        "array_labels = []\n",
        "\n",
        "for path in imagePaths:\n",
        "  array_of_videos2.append(load_frames(path, fr=3, max_frames = 100))\n",
        "  array_labels.append(0)\n",
        "\n",
        "array_labels.append(1)\n",
        "data2 = np.array(array_of_videos2)\n",
        "labels = np.array(array_labels[1:])\n",
        "\n",
        "np.save('data.npy', data2)\n",
        "np.save('labels.npy', labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alm7CSFqF7fb",
        "outputId": "f735945f-59d6-4658-ce6c-ee9fef8f788d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data.npy /content/drive/MyDrive/movie_data\n",
        "!cp /content/label.npy /content/drive/MyDrive/movie_data\n",
        "\n"
      ],
      "metadata": {
        "id": "HqWcTsM8NtXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create Dataset\n",
        "# from imutils import paths\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# # DATA PREPARATION\n",
        "# imagePaths = list(paths.list_files('/content/drive/MyDrive/movie_data'))\n",
        "# video_number = len(imagePaths)\n",
        "# # video_array = np.ndarzerosray((1, max_frames, 224, 224, 3), dtype=np.float32)\n",
        "# array_of_videos = []\n",
        "# array_labels = [1]\n",
        "# for path in imagePaths[:10]:\n",
        "#   array_of_videos.append(load_video(path, max_frames = 0))\n",
        "#   array_labels.append(0)\n",
        "# array_labels.remove(0)\n",
        "# data = np.array(array_of_videos)\n",
        "# labels = np.array(array_labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s_tVdLtbooPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrJBsrnCMqZy",
        "outputId": "3b3012fa-e9cc-45eb-8246-2f3ff877051a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35, 100, 224, 224, 3), (35,))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_i3d():\n",
        "    i3d = \"https://tfhub.dev/deepmind/i3d-kinetics-400/1\"\n",
        "    hub_layer = hub.KerasLayer(i3d,input_shape=[None,224,224,3],trainable=False)\n",
        "    model = tf.keras.Sequential()   \n",
        "  \n",
        "    \n",
        "    model.add(hub_layer)\n",
        "    model.add(tf.keras.layers.Dense(2, activation='softmax')) # change as per no of classes 20-5-21\n",
        "    opt = SGD(learning_rate=(0.002)) # 2*10^-3\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model \n",
        "    \n",
        "    \n",
        "   "
      ],
      "metadata": {
        "id": "ivaCoVnHHbsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdsaT2T2l2rl",
        "outputId": "8a243144-f190-4484-a6c2-2354ce3d6bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QV6GmMfbS-ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "\n",
        "# n_classes = 2\n",
        "# Xin, Yin = data2, labels\n",
        "# print(Xin.shape,Yin.shape)\n",
        "\n",
        "# Yin = np_utils.to_categorical(Yin,n_classes)\n",
        "# print(Xin[4].shape,Yin[1].shape)\n",
        "# vid = Xin[4]\n",
        "# print(Xin.shape,Yin.shape)\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(Xin, Yin, test_size=0.2, random_state=4)\n",
        "# print(\"coming back to main Split done size is:{0} and {1} \".format(X_train.shape,Y_train.shape))\n",
        "\n",
        "# #   30-05-2021\n",
        "# model = train_i3d()\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=2, epochs=10, verbose=1,shuffle=True)\n",
        "\n",
        "# # model.save_weights(\"/tf/i3d_finetuning/models/multiclass6_STA_npdi_i3d_lr_0.002_50_epochs_batch32.h5\")\n",
        "# loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "    \n",
        "    \n",
        "  \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSBdYndtIS_1",
        "outputId": "cb096cad-1d40-4deb-f583-2d3d4198e90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35, 100, 224, 224, 3) (35,)\n",
            "(100, 224, 224, 3) (2,)\n",
            "(35, 100, 224, 224, 3) (35, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def trim(video,i):\n",
        "#     #print(\"video.shape[0] \",video.shape[0])\n",
        "#     try:\n",
        "#         start = np.random.randint(0, video.shape[0] - (T+1)) #changed shape[1] to shape[0]\n",
        "#         end = start + T\n",
        "# #         print(\"======\")\n",
        "# #         print(\"=============\")\n",
        "# #         print(\"==========================\")\n",
        "#         #print(\"Start and end \",start,end)\n",
        "#         return np.array(video[start:end, :, :, :])\n",
        "#     except:\n",
        "#         # print(\"video.shape[0] \",video.shape[0],i)\n",
        "#         return np.random.rand(16,224,224,3)\n",
        "# def train_array(X_train):\n",
        "#     X = []\n",
        "#     i = 0\n",
        "#     for ele in X_train:\n",
        "#         print(\"shape\",ele.shape)\n",
        "#         i+=1\n",
        "#         if ele is not None:\n",
        "#             ele = trim(ele,i)\n",
        "#         else:\n",
        "#             ele =  np.random.rand(16,224,224,3)\n",
        "#         X.append(ele)\n",
        "#         print(\"shape\",ele.shape)\n",
        "#     print(\"from train array\",len(X))\n",
        "    \n",
        "#     return np.array(X).shape\n",
        "# print(train_array(data))\n"
      ],
      "metadata": {
        "id": "4V2FC3LTLzTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "VFALNvQ8S-hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_IMAGE_SIZE=224\n",
        "\n",
        "\n",
        "sample_input = np.zeros((5, 64, _IMAGE_SIZE, _IMAGE_SIZE, 3))\n",
        "Y = np.zeros((5,2))\n",
        "history = model.fit(sample_input, Y, epochs=10, verbose=1,shuffle=True)\n"
      ],
      "metadata": {
        "id": "a02U45TFR14B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.shape"
      ],
      "metadata": {
        "id": "RPnQ-dKWh9uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "metadata": {
        "id": "4GJ1l8wJKz9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(\n",
        "#   optimizer=tf.keras.optimizers.Adam(),\n",
        "#   loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#   metrics=['acc'])\n",
        "\n",
        "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "#     log_dir=log_dir,\n",
        "#     histogram_freq=1) # Enable histogram computation for every epoch."
      ],
      "metadata": {
        "id": "T3_bQZbOkgDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# labels = np.zeros((5) )\n",
        "# labels = np.append(labels, np.ones(5))\n",
        "# labels"
      ],
      "metadata": {
        "id": "j0lFVhLq5f9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# lb = LabelBinarizer()\n",
        "# labels = lb.fit_transform(labels)\n",
        "# labels.shape"
      ],
      "metadata": {
        "id": "17zmKVi-59Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# NUM_EPOCHS = 2\n",
        "# (trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "# \ttest_size=0.25, stratify=labels, random_state=42)\n",
        "\n",
        "# # H = model.fit(\n",
        "# # \tx=trainAug.flow(trainX, trainY, batch_size=32),\n",
        "# # \tsteps_per_epoch=len(trainX) // 32,\n",
        "# # \tvalidation_data=valAug.flow(testX, testY),\n",
        "# # \tvalidation_steps=len(testX) // 32,\n",
        "# # \tepochs=args[\"epochs\"])\n",
        "\n",
        "# history = model.fit(x = trainX, y = trainY, epochs=NUM_EPOCHS )\n",
        "\n",
        "#                     #callbacks=tensorboard_callback)"
      ],
      "metadata": {
        "id": "p4PdesjKoVcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EaUWj6k95va4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}